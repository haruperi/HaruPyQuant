# Instructions

During your interaction with the user, if you find anything reusable in this project (e.g. version of a library, model name), especially about a fix to a mistake you made or a correction you received, you should take note in the `Lessons` section in the `.cursorrules` file so you will not make the same mistake again. 

You should also use the `.cursorrules` file as a Scratchpad to organize your thoughts. Especially when you receive a new task, you should first review the content of the Scratchpad, clear old different task if necessary, first explain the task, and plan the steps you need to take to complete the task. You can use todo markers to indicate the progress, e.g.
[X] Task 1
[ ] Task 2

Also update the progress of the task in the Scratchpad when you finish a subtask.
Especially when you finished a milestone, it will help to improve your depth of task accomplishment to use the Scratchpad to reflect and plan.
The goal is to help you maintain a big picture as well as the progress of the task. Always refer to the Scratchpad when you plan the next step.

# Utils Tools

Note all the utils tools are in python. So in the case you need to do batch processing, you can always consult the python files and write your own script.

## Screenshot Verification

The screenshot verification workflow allows you to capture screenshots of web pages and verify their appearance using LLMs. The following utils tools are available:

1. Screenshot Capture:
```bash
venv/bin/python utils/screenshot_utils.py URL [--output OUTPUT] [--width WIDTH] [--height HEIGHT]
```

2. LLM Verification with Images:
```bash
venv/bin/python tools/llm_api.py --prompt "Your verification question" --provider {openai|anthropic} --image path/to/screenshot.png
```

Example workflow:
```python
from screenshot_utils import take_screenshot_sync
from llm_api import query_llm

# Take a screenshot

screenshot_path = take_screenshot_sync('https://example.com', 'screenshot.png')

# Verify with LLM

response = query_llm(
    "What is the background color and title of this webpage?",
    provider="openai",  # or "anthropic"
    image_path=screenshot_path
)
print(response)
```

## LLM

You always have an LLM at your side to help you with the task. For simple tasks, you could invoke the LLM by running the following command:
```
venv/bin/python app/utils/llm_api.py --prompt "What is the capital of France?" --provider "anthropic"
```

The LLM API supports multiple providers:
- OpenAI (default, model: gpt-4o)
- Azure OpenAI (model: configured via AZURE_OPENAI_MODEL_DEPLOYMENT in .env file, defaults to gpt-4o-ms)
- DeepSeek (model: deepseek-chat)
- Anthropic (model: claude-3-sonnet-20240229)
- Gemini (model: gemini-pro)
- Local LLM (model: Qwen/Qwen2.5-32B-Instruct-AWQ)

But usually it's a better idea to check the content of the file and use the APIs in the `app/utils/llm_api.py` file to invoke the LLM if needed.

## Web browser

You could use the `app/utils/web_scraper.py` file to scrape the web.
```
venv/bin/python app/utils/web_scraper.py --max-concurrent 3 URL1 URL2 URL3
```
This will output the content of the web pages.

## Search engine

You could use the `app/utils/search_engine.py` file to search the web.
```
venv/bin/python app/utils/search_engine.py "your search keywords"
```
This will output the search results in the following format:
```
URL: https://example.com
Title: This is the title of the search result
Snippet: This is a snippet of the search result
```
If needed, you can further use the `web_scraper.py` file to scrape the web page content.

# Development Guidelines

1. Always activate the virtual environment before working on the project
2. Add new dependencies to requirements.txt
3. Keep code organized and well-documented
4. Follow PEP 8 style guidelines for Python code
5. Keep your code DRY (Dont Repeat Yourself)

# Lessons

## User Specified Lessons

- For method signature mismatches in strategy classes:
  - Always check the method signature in the base class (BaseStrategy) before calling methods
  - The get_trade_parameters method takes 4 parameters: (self, df, df_core, action, symbol_info)
  - Do not pass mt5_client as a parameter to get_trade_parameters - it's already available as self.mt5_client
  - Verify method calls match the exact signature to avoid "takes X positional arguments but Y were given" errors
  - When inheriting from BaseStrategy, ensure all method calls follow the base class signature
- For Unicode encoding issues on Windows:
  - Windows console (cp1252 encoding) cannot handle Unicode emoji characters
  - Remove emoji characters from notification template titles to avoid UnicodeEncodeError
  - Use custom UnicodeStreamHandler for Windows to handle Unicode characters properly
  - Test notification templates on Windows to ensure compatibility
- For NotificationResult attribute access:
  - Always use `result.error_message` instead of `result.error` when accessing error information
  - The NotificationResult class has `error_message` attribute, not `error` attribute
  - Check the NotificationResult class definition for correct attribute names
  - Common attributes: success, message_id, error_message, timestamp, retry_count, delivery_time_ms
- You have a python venv in ./venv. Use it.
- Include info useful for debugging in the program output.
- Read the file before you try to edit it.
- Due to Cursor's limit, when you use `git` and `gh` and need to submit a multiline commit message, first write the message in a file, and then use `git commit -F <filename>` or similar command to commit. And then remove the file. 
- For Project Implementation tasks:
  - Work on one task at a time
  - After completing a task:
    1. Mark it as done in the todo list
    2. Create a git commit 
    3. Ask for confirmation before proceeding to the next task
  - Do not automatically proceed to the next task without explicit confirmation
- Always implement proper logging in all modules following these guidelines:
  1. Import the logger at the top of each module: `from utils import get_logger`
  2. Create a module-specific logger: `logger = get_logger(__name__)`
  3. Use appropriate log levels:
     - DEBUG: Detailed information for debugging
     - INFO: Confirmation that things are working as expected
     - WARNING: Indication that something unexpected happened but the application is still working
     - ERROR: Due to a more serious problem, the application couldn't perform a function
     - CRITICAL: A serious error indicating the application may be unable to continue running
  4. Include context in log messages (e.g., function parameters, return values, object states)
  5. Log the start and end of important operations
  6. Log all exceptions with traceback information using `logger.exception()` or `logger.error(exc_info=True)`
  7. Use structured logging for machine-parseable logs when appropriate
- Implement defensive programming to handle circular imports:
  1. Use try/except blocks for imports that might cause circular dependencies
  2. Implement fallback mechanisms for critical utilities like logging
  3. Follow the module hierarchy defined in docs/dependency_management.md
  4. Use late imports inside functions when necessary
  5. Use dependency injection to pass higher-level components to lower-level ones
  6. Test imports thoroughly before committing code
- For pandas_ta compatibility issues:
  - pandas_ta has compatibility problems with newer numpy versions (NaN vs nan)
  - Use local indicator functions from app/strategy/indicators.py instead of pandas_ta
  - Local indicators provide better control and avoid external dependency issues
  - When running Python modules, use `venv\Scripts\python -m app.module.submodule` instead of `python -m app.module.submodule` to ensure virtual environment is used
  - Always check if dependencies are properly installed in the virtual environment before running modules

## Cursor learned

## Crash Recovery Lessons

- Implement comprehensive crash recovery systems with multiple layers:
  1. **Exception Handling**: Use context managers for automatic exception capture and logging
  2. **State Persistence**: Save system state to JSON files for recovery across restarts
  3. **Health Monitoring**: Monitor CPU, memory, and disk usage with configurable thresholds
  4. **Recovery Callbacks**: Allow custom recovery procedures for different components
  5. **Graceful Shutdown**: Implement proper cleanup procedures with signal handling
  6. **Watchdog Service**: External process monitoring for automatic restart on crashes

- Use psutil library for system resource monitoring and process management
- Implement defensive programming with proper error handling and logging
- Use dataclasses for structured state management with JSON serialization
- Register cleanup callbacks with atexit for guaranteed execution
- Use threading for background health monitoring without blocking main operations
- Implement PID file management for watchdog service process tracking
- Use subprocess.Popen for external process management with proper cleanup
- Design recovery systems with configurable limits and delays to prevent rapid restart loops
- Implement comprehensive logging with context information for debugging
- Use signal handlers (SIGINT, SIGTERM) for graceful shutdown procedures
- Create test scripts that simulate various failure scenarios for validation
- Document crash recovery systems thoroughly with usage examples and best practices

- For search results, ensure proper handling of different character encodings (UTF-8) for international queries
- Add debug information to stderr while keeping the main output clean in stdout for better pipeline integration
- When using seaborn styles in matplotlib, use 'seaborn-v0_8' instead of 'seaborn' as the style name due to recent seaborn version changes
- Use 'gpt-4o' as the model name for OpenAI's GPT-4 with vision capabilities
- For MT5 integration, use the correct path format with double backslashes and include the broker name in the path: `C:\\Program Files\\Pepperstone MetaTrader 5\\terminal64.exe` instead of `C:\\Program Files\\MetaTrader 5\\terminal64.exe`
- When working with MT5, check if the terminal path exists before attempting to initialize the connection to avoid cryptic errors
- In PowerShell, use semicolon (;) instead of && for command chaining
- When creating test files, define path constants in the main module to make it more testable and avoid hardcoding paths in multiple places
- Use unittest.mock.patch to mock module-level variables during testing
- Use Decimal for financial calculations to avoid floating-point precision issues
- Implement proper validation in data classes using __post_init__ for type conversion and validation
- Design abstract base classes with comprehensive documentation and clear error messages
- Cache frequently accessed data in data providers to improve performance
- When testing file operations like log rotation:
   - Use smaller file sizes in tests to trigger rotation quickly
   - Add proper cleanup of file handlers
   - Include sufficient wait time for file operations
- Make configuration parameters flexible:
   - Allow customization of log rotation settings
   - Use sensible defaults for production
   - Document all parameters clearly
- When mocking objects in Python tests:
   - Set attributes directly on MagicMock objects to avoid attribute access issues
   - Mock all necessary dependencies including file system operations
   - Properly handle initialization and cleanup in fixtures
   - Use proper error handling and status checking in connection methods
   - Mock both success and failure cases for comprehensive testing
- For DataFrame operations with dynamic indexing:
   - Always check bounds before using relative group IDs (e.g., group_id - 2)
   - Verify DataFrame is not empty before accessing with .iloc[-1] or similar
   - Add defensive checks like `if len(dataframe) > 0:` before data access
   - Use proper bounds checking when iterating over grouped data to prevent IndexError


## MT5 Integration Lessons

1. When working with MT5 API:
   - Use `trade_tick_size` and `trade_contract_size` instead of `tick_size` and `contract_size`
   - Convert numeric values to appropriate types (float, int) to ensure consistency
   - Handle spread_float as a float value derived from spread
   - Properly handle numpy arrays returned by `copy_rates_range`
   - Always use capitalized OHLCV column names ('Open', 'High', 'Low', 'Close', 'Volume') for consistency with MT5 DataFrame output
   - Handle data type differences: MT5 returns Volume as uint64, but SQLite expects int64
   - When accessing MT5 symbol info, use `getattr(symbol_info, 'point', default_value)` instead of dictionary access since MT5 returns named tuples, not dictionaries
   - Run Python modules from project root using `python -m app.module.submodule` instead of `python path/to/file.py` to avoid import issues
   - When using real MT5 data for testing, be aware of data availability limits (e.g., EURUSD history from 2015)
   - Handle DataFrame index properly when MT5 returns data with timestamp as index
- Use consistent timezone handling: `datetime.now()` for local time and `datetime.now(timezone.utc)` for UTC time, but be consistent within the same application context
- For notification messages, ensure both the message header timestamp and body timestamps use the same timezone to avoid confusion
- When calling MT5Client.fetch_data(), always pass datetime objects for start_date and end_date parameters, not strings:
  - Use `datetime(2025, 1, 1, tzinfo=timezone.utc)` instead of `"2025-01-01"`
  - Import datetime and timezone: `from datetime import datetime, timezone`
  - Always use UTC timezone for consistency with MT5 data
- For dual MT5 client setups: Use broker 1 for main trading data and broker 3 for index data when different brokers have access to different symbol types
- When working with MT5 tick data in streaming:
  - MT5 returns tick data as named tuples, not dictionaries
  - Use `tick._asdict()` to convert to dictionary format
  - Always validate required fields before processing
  - Handle both named tuple and dictionary formats for compatibility
  - Use type ignore comments for type checker issues with MT5 data structures
  - Always pass a symbol parameter to `get_tick()` method (e.g., `get_tick("EURUSD")`)
  - Access tick data as dictionary keys (e.g., `tick['time']`) after conversion
- For MT5 symbol initialization:
  - Always check if symbols are already visible before attempting to add them
  - Verify symbol availability from broker before attempting to add to market watch
  - Use proper symbol mapping for different brokers (e.g., _ecn suffix for broker 3)
  - Implement retry mechanism for failed symbol additions
  - Provide detailed logging for debugging symbol initialization issues
  - Check both availability and visibility status separately
  - Use `mt5.symbol_select()` to add symbols to market watch
  - Verify symbol visibility after addition using `symbol_info.visible`

2. Environment Variable Handling:
   - Strip comments from environment variable values before using them
   - Use helper functions to handle environment variable parsing and type conversion
   - Provide sensible defaults for optional configuration values

3. Integration Testing:
   - Use real MT5 credentials from environment variables
   - Test both successful and error cases
   - Verify data types and value ranges
   - Test with multiple symbols and timeframes
   - Clean up resources (disconnect) after tests

4. Error Handling:
   - Check for None return values from MT5 API calls
   - Use mt5.last_error() to get detailed error information
   - Log errors with context information
   - Implement proper cleanup in error cases

5. Connection Management:
   - Verify terminal path exists before connecting
   - Handle connection timeouts
   - Implement proper cleanup on object destruction
   - Track connection state accurately


## Testing Rules

All tests must be organized in the following directory structure under the tests folder:

### Unit Tests (`tests/unit/`)
- Purpose: Test individual components/functions in isolation
- Scope: Single unit of code (class, function, method)
- Dependencies: Usually mocked/stubbed
- Examples:
  - `tests/unit/utils/test_logger.py` - Tests individual logger functions
  - `tests/unit/core/test_mt5_data.py` - Tests MT5 data parsing functions
  - `tests/unit/trader/test_position.py` - Tests position calculation logic

### Integration Tests (`tests/integration/`)
- Purpose: Test how components work together
- Scope: Multiple components/services
- Dependencies: Real or test doubles
- Examples:
  - `tests/integration/test_mt5_trader.py` - Tests MT5 client with trading logic
  - `tests/integration/test_db_logging.py` - Tests logger with database
  - `tests/integration/test_strategy_execution.py` - Tests strategy with live data feed

### End-to-End Tests (`tests/e2e/`)
- Purpose: Test complete workflows
- Scope: Entire system
- Dependencies: Real systems
- Examples:
  - `tests/e2e/test_trading_workflow.py` - Complete trade lifecycle
  - `tests/e2e/test_backtest_workflow.py` - Full backtest process
  - `tests/e2e/test_dashboard_workflow.py` - Complete dashboard interaction

### Fixtures (`tests/fixtures/`)
- Purpose: Provide reusable test data and setup
- Types:
  - Data fixtures: Sample data for tests (e.g., OHLCV data)
  - Object fixtures: Pre-configured objects (e.g., MT5 API mock)
  - Environment fixtures: Test environment setup (e.g., test database)
- Examples:
  - `tests/fixtures/market_data.py` - Sample OHLCV data
  - `tests/fixtures/mt5_mock.py` - MT5 API mock
  - `tests/fixtures/test_db.py` - Test database setup

### Test File Organization
Test files must follow these naming conventions:
- All test files must be named `test_*.py` to be automatically discovered by test runners
- Test classes must be named `Test*`
- Test methods must be named `test_*`
- Unit test files should mirror the structure of the source code:
  - For a source file at `app/utils/logger.py`, the test should be at `tests/unit/utils/test_logger.py`
  - For a source file at `app/core/trade.py`, the test should be at `tests/unit/core/test_trade.py`

### Test Organization Guidelines
- Keep test files focused and cohesive
- Group related test cases in test classes
- Use descriptive test names that explain the scenario being tested
- Follow the Arrange-Act-Assert pattern in test methods
- Use appropriate fixtures for test setup and teardown
- Mock external dependencies in unit tests

### Tool Tests (`tests/tools/`)
- Purpose: Test development tools and scripts
- Scope: Development utilities and helper scripts
- Dependencies: Usually real dependencies (not mocked)
- Examples:
  - `tests/tools/test_logger.py` - Manual logger testing script
  - `tests/tools/test_db_setup.py` - Database setup verification
  - `tests/tools/test_env_check.py` - Environment setup verification

## Parameter Optimization Lessons

1. Optimization Methods:
   - Use grid search for thorough parameter space exploration
   - Use random search for faster optimization with large parameter spaces
   - Use walk-forward analysis to test parameter stability over time

2. Performance Metrics:
   - Sharpe ratio is the default optimization metric
   - Consider multiple metrics for robust strategy evaluation
   - Use walk-forward analysis to prevent overfitting

3. Parallel Processing:
   - Use ProcessPoolExecutor for parallel parameter evaluation
   - Set n_jobs to None for using all available CPU cores
   - Handle process pool cleanup properly

4. Memory Management:
   - Clear results after optimization to free memory
   - Use generators for large parameter combinations
   - Implement proper cleanup in error cases

## SQLite Integration Lessons

1. SQLite Datetime Handling:
   - Use ISO format for storing datetime strings to preserve timezone info
   - Always convert timestamps to UTC before storing
   - Parse timestamps with timezone info when retrieving
   - Handle naive timestamps by assuming UTC
   - Use timezone-aware datetime objects consistently
   - Verify timezone handling in integration tests
   - Store timezone information in ISO format strings
   - Use datetime.fromisoformat for parsing stored timestamps
   - Ensure DataFrame index has consistent timezone info
   - Convert all timestamps to UTC for storage and comparison

2. Data Validation:
   - Validate DataFrame structure before database operations
   - Check for required columns and data types
   - Verify timestamp format and timezone info
   - Ensure data consistency across operations
   - Handle edge cases in data validation
   - Log validation failures for debugging
   - Implement retry mechanisms for failed operations
   - Use proper error handling and logging
   - Keep validation rules consistent across modules
   - Document validation requirements clearly

3. Performance Optimization:
   - Use batch operations for better performance
   - Implement connection pooling
   - Add query optimization
   - Create proper indexes
   - Monitor query performance
   - Cache frequently accessed data
   - Use efficient data structures
   - Minimize database round trips
   - Handle large datasets efficiently
   - Profile and optimize critical paths


# Scratchpad

## Current Task: Refactor Strategy Methods - COMPLETED ✅

### Task Description:
Refactor `get_entry_signal()` and `get_exit_signal()` methods to take `data` as argument instead of `time`, and return entry/exit signals and times directly.

### Progress:
- [X] Refactor `get_entry_signal()` to take DataFrame as argument
- [X] Refactor `get_exit_signal()` to take DataFrame as argument
- [X] Remove dependency on `self.data` and `time` parameter
- [X] Use `data.index[-1]` for current timestamp
- [X] Use `data.iloc[-1]` for current row data
- [X] Update method signatures and docstrings

### Implementation Plan:
1. ✅ Change `get_entry_signal(time)` to `get_entry_signal(data: pd.DataFrame)`
2. ✅ Change `get_exit_signal(time)` to `get_exit_signal(data: pd.DataFrame)`
3. ✅ Replace `self.data.loc[:time]` with `data`
4. ✅ Replace `time` parameter with `data.index[-1]` for timestamps
5. ✅ Update all data access to use `data.iloc[-1]` for current row
6. ✅ Update docstrings and type hints

### Files Updated:
- ✅ `app/strategy/base.py` - Refactored both methods to use DataFrame argument

### Key Improvements Made:
- ✅ **Better API Design**: Methods now take DataFrame instead of time parameter
- ✅ **Reduced Dependencies**: No longer depends on `self.data` instance variable
- ✅ **More Flexible**: Can work with any DataFrame passed as argument
- ✅ **Cleaner Interface**: Direct access to current row data via `data.iloc[-1]`
- ✅ **Better Type Safety**: Proper type hints for DataFrame parameter
- ✅ **Consistent Pattern**: Both methods follow same parameter pattern

### Method Signatures:
```python
def get_entry_signal(self, data: pd.DataFrame) -> tuple[int, Optional[datetime]]:
    """
    :param data: DataFrame with market data including Signal column
    :return: Entry signal of the current row and entry time
    """

def get_exit_signal(self, data: pd.DataFrame) -> tuple[float, Optional[datetime]]:
    """
    :param data: DataFrame with market data including High, Low, High_time, Low_time columns
    :return: P&L of the position IF we close it and exit time
    """
```

### Usage Example:
```python
# Before (old way)
entry_signal, entry_time = strategy.get_entry_signal(current_time)
exit_signal, exit_time = strategy.get_exit_signal(current_time)

# After (new way)
entry_signal, entry_time = strategy.get_entry_signal(current_data)
exit_signal, exit_time = strategy.get_exit_signal(current_data)
```

### Benefits:
- ✅ **More Flexible**: Can work with any DataFrame, not just instance data
- ✅ **Better Testing**: Easier to test with mock DataFrames
- ✅ **Cleaner Code**: No dependency on instance variables
- ✅ **Future-Proof**: Better separation of concerns
- ✅ **Consistent API**: Both methods follow same pattern

### Previous Task: Add Type, MAE, and MFE Columns to HTML Plot Trades Table - COMPLETED ✅

### Task Description:
Add Type, MAE, and MFE columns to the trades table in the HTML plot for better trade analysis visualization.

### Progress:
- [X] Analyze the plotting code structure in _plotting.py
- [X] Identify the _plot_trades_section function
- [X] Add Type column to the trades table
- [X] Add MAE column to the trades table (formatted in pips)
- [X] Add MFE column to the trades table (formatted in pips)
- [X] Test the functionality with sample data

### Implementation Plan:
1. ✅ Analyze the plotting code structure in _plotting.py
2. ✅ Identify the _plot_trades_section function
3. ✅ Add Type column to the trades table
4. ✅ Add MAE column to the trades table (formatted in pips)
5. ✅ Add MFE column to the trades table (formatted in pips)
6. ✅ Document the functionality

### Files Updated:
- ✅ `app/backtesting/_plotting.py` - Added Type, MAE, and MFE columns to trades table

### Key Features Added:
- ✅ Type column showing "Buy" or "Sell" in the HTML plot
- ✅ MAE column showing Maximum Adverse Excursion in pips
- ✅ MFE column showing Maximum Favorable Excursion in pips
- ✅ Proper formatting for MAE and MFE (0.0 decimal places)
- ✅ Integration with existing trades table structure
- ✅ Sortable columns for easy analysis

### HTML Plot Trades Table Columns:
1. Entry Time
2. Exit Time
3. Entry Price
4. Exit Price
5. Size
6. **Type** (new)
7. Return %
8. Profit/Loss
9. **MAE (pips)** (new)
10. **MFE (pips)** (new)
11. Duration

### Usage:
```python
from backtesting import Backtest
from app.strategy.simple_scalping import SimpleScalpingStrategy

# Run backtest
bt = Backtest(data, SimpleScalpingStrategy, cash=10000, commission=.002)
stats = bt.run()

# Plot with enhanced trades table
bt.plot(plot_trade_table=True)
```

### Benefits:
- ✅ **Visual Trade Analysis**: See trade direction, MAE, and MFE directly in the plot
- ✅ **Quick Filtering**: Sort by Type, MAE, or MFE for analysis
- ✅ **Risk Assessment**: Identify trades with high MAE or low MFE
- ✅ **Direction Analysis**: Compare Buy vs Sell performance visually
- ✅ **Professional Output**: Clean, formatted table in HTML plots

### Previous Task: Add Trade Type Column to Trades DataFrame - COMPLETED ✅

### Task Description:
Add a "Type" column to the trades DataFrame that shows "Buy" for long trades and "Sell" for short trades, making it easier to analyze trade direction.

### Progress:
- [X] Analyze how trade direction is determined from trade size
- [X] Add Type column calculation to _stats.py
- [X] Update rearrange_trades_columns function to include Type column
- [X] Update example scripts to include Type column
- [X] Test the functionality with sample data

### Implementation Plan:
1. ✅ Analyze how trade direction is determined from trade size
2. ✅ Add Type column calculation to _stats.py
3. ✅ Update rearrange_trades_columns function to include Type column
4. ✅ Update example scripts to include Type column
5. ✅ Document the functionality

### Files Updated:
- ✅ `app/backtesting/_stats.py` - Added Type column calculation
- ✅ `app/util/helper.py` - Updated rearrange_trades_columns function
- ✅ `scripts/rearrange_trades_example.py` - Updated with Type column
- ✅ `scripts/mae_mfe_example.py` - Updated with Type column

### Key Features Added:
- ✅ Type column showing "Buy" for long trades (positive size)
- ✅ Type column showing "Sell" for short trades (negative size)
- ✅ Easy filtering and analysis by trade direction
- ✅ Integration with existing trades DataFrame structure
- ✅ Updated column order to include Type

### Updated Column Order:
1. EntryTime
2. EntryPrice
3. ExitTime
4. ExitPrice
5. Size
6. **Type** (new)
7. SL
8. TP
9. PnLPips
10. PnL
11. ReturnPct
12. Commission
13. MAE (in pips)
14. MFE (in pips)
15. Duration
16. EntryBar
17. ExitBar
18. Tag

### Usage:
```python
from app.util.helper import rearrange_trades_columns

# After running backtest
stats = bt.run()
rearranged_trades = rearrange_trades_columns(stats._trades)

# Filter by trade type
buy_trades = rearranged_trades[rearranged_trades['Type'] == 'Buy']
sell_trades = rearranged_trades[rearranged_trades['Type'] == 'Sell']

# Analyze performance by direction
print(f"Buy trades: {len(buy_trades)}")
print(f"Sell trades: {len(sell_trades)}")
```

### Trade Type Analysis:
- **Buy Trades**: Long positions (positive size)
- **Sell Trades**: Short positions (negative size)
- **Direction Analysis**: Compare performance between long and short trades
- **Strategy Optimization**: Identify which direction performs better

### Previous Task: Add Commission Data to Trades DataFrame - COMPLETED ✅

### Task Description:
Add commission data to the trades DataFrame and include it in the column rearrangement. Commission shows the trading costs for each individual trade.

### Progress:
- [X] Analyze how commissions are stored in the Trade class
- [X] Add commission data collection to _stats.py
- [X] Update rearrange_trades_columns function to include Commission column
- [X] Update example scripts to include commission data
- [X] Test the functionality with sample data

### Implementation Plan:
1. ✅ Analyze how commissions are stored in Trade objects
2. ✅ Add commission data collection to _stats.py
3. ✅ Update rearrange_trades_columns function to include Commission column
4. ✅ Update example scripts to include commission data
5. ✅ Document the functionality

### Files Updated:
- ✅ `app/backtesting/_stats.py` - Added commission data collection
- ✅ `app/util/helper.py` - Updated rearrange_trades_columns function
- ✅ `scripts/rearrange_trades_example.py` - Updated with Commission column
- ✅ `scripts/mae_mfe_example.py` - Updated with commission data

### Key Features Added:
- ✅ Commission data for each individual trade
- ✅ Commission values in dollars (consistent with broker calculations)
- ✅ Integration with existing trades DataFrame structure
- ✅ Updated column order to include Commission

### Updated Column Order:
1. EntryTime
2. EntryPrice
3. ExitTime
4. ExitPrice
5. Size
6. SL
7. TP
8. PnLPips
9. PnL
10. ReturnPct
11. **Commission** (new)
12. MAE (in pips)
13. MFE (in pips)
14. Duration
15. EntryBar
16. ExitBar
17. Tag

### Usage:
```python
from app.util.helper import rearrange_trades_columns

# After running backtest
stats = bt.run()
rearranged_trades = rearrange_trades_columns(stats._trades)
print(rearranged_trades[['Commission', 'PnL', 'PnLPips']])  # View costs and profits
```

### Commission Analysis:
- **Individual Trade Costs**: See commission for each trade
- **Net Profit Calculation**: PnL - Commission = Net Profit
- **Cost Analysis**: Compare commission costs across different trade sizes
- **Profitability Assessment**: Account for trading costs in strategy evaluation

### Previous Task: Add MAE and MFE Calculations to Trades DataFrame - COMPLETED ✅

### Task Description:
Add MAE (Maximum Adverse Excursion) and MFE (Maximum Favorable Excursion) calculations to the trades DataFrame and include them in the column rearrangement. Updated to calculate in pips instead of percentages.

### Progress:
- [X] Analyze the backtesting framework structure
- [X] Implement MAE and MFE calculations in _stats.py (in pips)
- [X] Update rearrange_trades_columns function to include new columns
- [X] Create comprehensive example scripts
- [X] Test the functionality with sample data

### Implementation Plan:
1. ✅ Analyze how trades DataFrame is created in backtesting framework
2. ✅ Add MAE and MFE calculations to _stats.py (in pips)
3. ✅ Update rearrange_trades_columns function to include new columns
4. ✅ Create example scripts for demonstration
5. ✅ Document the functionality

### Files Updated:
- ✅ `app/backtesting/_stats.py` - Added MAE and MFE calculations in pips
- ✅ `app/util/helper.py` - Updated rearrange_trades_columns function
- ✅ `scripts/rearrange_trades_example.py` - Updated with MAE/MFE columns in pips
- ✅ `scripts/mae_mfe_example.py` - Created comprehensive example with pips calculation

### Key Features Added:
- ✅ MAE (Maximum Adverse Excursion) calculation for each trade in pips
- ✅ MFE (Maximum Favorable Excursion) calculation for each trade in pips
- ✅ Proper handling of long vs short trades
- ✅ Pip-based calculations for easy forex interpretation
- ✅ Integration with existing trades DataFrame structure
- ✅ Updated column order to include MAE and MFE

### MAE/MFE Calculation Logic (in pips):
- **Long Trades**: 
  - MAE = (Lowest Low - Entry Price) × 10000 pips
  - MFE = (Highest High - Entry Price) × 10000 pips
- **Short Trades**:
  - MAE = (Entry Price - Highest High) × 10000 pips
  - MFE = (Entry Price - Lowest Low) × 10000 pips

### Updated Column Order:
1. EntryTime
2. EntryPrice
3. ExitTime
4. ExitPrice
5. Size
6. SL
7. TP
8. PnLPips
9. PnL
10. ReturnPct
11. Duration
12. EntryBar
13. ExitBar
14. Tag

### Previous Task: Fix BackTradeStrategy Initialization - COMPLETED ✅

### Task Description:
Fix the TypeError where `BackTradeStrategy.__init__()` was getting multiple values for argument 'parameters' because the Backtest framework expects the `init` method to take no arguments.

### Progress:
- [X] Identify the initialization error in backtrader.py
- [X] Fix the BackTradeStrategy class to use class variables instead of instance variables
- [X] Update the init method to be compatible with the Backtest framework
- [X] Fix position sizing calculation to work with Backtest framework requirements
- [X] Test the fix to ensure backtrader script runs successfully

### Implementation Plan:
1. ✅ Analyze the error message and identify the root cause (Backtest framework compatibility issue)
2. ✅ Convert instance variables to class variables for MT5 client and symbol info
3. ✅ Update init method signature to match Backtest framework expectations
4. ✅ Fix position sizing calculation to use appropriate fractions of equity
5. ✅ Test the fix to ensure successful backtest execution

### Files Updated:
- ✅ `app/strategy/backtrader.py` - Fixed BackTradeStrategy class structure
- ✅ `app/strategy/backtrader.py` - Updated init method signature
- ✅ `app/strategy/backtrader.py` - Fixed position sizing calculation

### Key Fixes Made:
- ✅ Changed from instance variables to class variables for MT5 client and symbol info
- ✅ Updated init method to take no arguments (compatible with Backtest framework)
- ✅ Fixed position sizing to use appropriate fractions of equity (1% cap)
- ✅ Added debugging output to verify initialization

### Issues Fixed:
- ✅ TypeError: BackTradeStrategy.__init__() got multiple values for argument 'parameters'
- ✅ AssertionError: size must be a positive fraction of equity
- ✅ Insufficient margin warnings due to oversized positions
- ✅ Backtest framework compatibility issues

### Previous Task: Fix Look-Ahead Bias Issue - IN PROGRESS 🔄

### Task Description:
Fix the look-ahead bias error where the risk manager is detecting future data timestamps. The error shows that the last bar time (2025-07-29 00:00:00+00:00) is in the future compared to the current time (2025-07-28 22:36:30+00:00).

### Progress:
- [X] Identify the look-ahead bias error in risk_manager.py
- [X] Fix the D1 timeframe check to use proper datetime comparison instead of string comparison
- [X] Increase buffer time from 5 minutes to 30 minutes to handle timezone differences
- [X] Add better debugging logs to understand the timezone issue
- [X] Improve D1 data filtering to remove future bars (next day)
- [ ] Test the fix to ensure look-ahead bias is resolved

### Implementation Plan:
1. ✅ Analyze the error message and identify the root cause (timezone/time difference issue)
2. ✅ Fix the D1 timeframe check to use proper datetime comparison
3. ✅ Increase buffer time to handle server timezone differences
4. ✅ Add debugging logs to understand the timezone issue
5. ✅ Improve D1 data filtering to handle future bars
6. [ ] Test the fix to ensure look-ahead bias is resolved

### Files Updated:
- ✅ `app/trading/risk_manager.py` - Fixed D1 timeframe check and increased buffer time
- ✅ `app/trading/risk_manager.py` - Added debugging logs for timezone analysis
- ✅ `app/trading/risk_manager.py` - Improved D1 data filtering to handle future bars

### Key Fixes Made:
- ✅ Changed string comparison to proper datetime comparison for D1 timeframe
- ✅ Increased buffer time from 5 minutes to 30 minutes for timezone differences
- ✅ Added debugging logs to track current time vs bar time
- ✅ Improved D1 filtering to remove bars from current or future dates
- ✅ Added time difference logging for better error analysis

### Issues Fixed:
- ✅ Unreliable string comparison for D1 timeframe check
- ✅ Insufficient buffer time for server timezone differences
- ✅ Missing debugging information for timezone analysis
- ✅ D1 data filtering not handling future bars properly

### Previous Task: Fix Import Error - COMPLETED ✅

### Task Description:
Fix the ImportError where `get_adr` cannot be imported from `app.strategy.indicators` because the function is actually named `adr`.

### Progress:
- [X] Identify the import error in risk_manager.py
- [X] Fix the import statement in risk_manager.py to use 'adr' instead of 'get_adr'
- [X] Fix the function call in risk_manager.py to use 'adr' instead of 'get_adr'
- [X] Fix the import statement in swing_trend_momentum.py to use 'adr' instead of 'get_adr'
- [X] Fix the function call in swing_trend_momentum.py to use 'adr' instead of 'get_adr'
- [X] Add import statement in base.py for 'adr' from indicators module
- [X] Fix the function call in base.py to use 'adr' instead of 'get_adr'

### Implementation Plan:
1. ✅ Analyze the error message and identify the root cause (function name mismatch)
2. ✅ Fix all import statements to use the correct function name 'adr'
3. ✅ Fix all function calls to use the correct function name 'adr'
4. ✅ Add missing import statements where needed
5. ✅ Test the fix to ensure circular import is resolved

### Files Updated:
- ✅ `app/trading/risk_manager.py` - Fixed import and function call
- ✅ `app/strategy/swing_trend_momentum.py` - Fixed function call
- ✅ `app/strategy/base.py` - Added import and fixed function call

### Key Fixes Made:
- ✅ Changed `from app.strategy.indicators import get_adr` to `from app.strategy.indicators import adr`
- ✅ Changed all `get_adr()` function calls to `adr()`
- ✅ Added missing import statement in base.py
- ✅ Resolved circular import dependency issue

### Issues Fixed:
- ✅ ImportError: cannot import name 'get_adr' from 'app.strategy.indicators'
- ✅ Function name mismatch between import and actual function name
- ✅ Missing import statements in some files
- ✅ Circular import dependency causing module loading failures

### Previous Task: EMA Signal Integration - COMPLETED ✅

### Task Description:
Merge the EMA signal logic from the notebook into the get_signals function in simple_scalping.py to add EMA-based trading signals.

### Progress:
- [X] Analyze the EMA signal logic from the notebook
- [X] Add backcandles parameter to strategy parameters
- [X] Implement EMA signal calculation function
- [X] Integrate EMA signal logic into get_signals function
- [X] Optimize performance for large datasets
- [X] Test the integration with signals_df module
- [X] Fix backtesting framework SL/TP validation issues
- [X] Implement complete backtesting functionality
- [X] Update documentation

### Implementation Plan:
1. ✅ Analyze the notebook EMA signal logic and understand the requirements
2. ✅ Add backcandles parameter to default_params
3. ✅ Create ema_signal method for calculating individual signals
4. ✅ Integrate EMA signal calculation into get_signals function
5. ✅ Optimize performance by avoiding unnecessary DataFrame copies
6. ✅ Test the integration with real data
7. ✅ Fix backtesting framework order validation issues
8. ✅ Implement complete backtesting with proper SL/TP calculations
9. ✅ Update documentation

### Files Updated:
- ✅ `app/strategy/simple_scalping.py` - Added EMA signal logic, backcandles parameter, and complete backtesting functionality
- ✅ `.cursorrules` - Updated with current task progress

### Key Features Added:
- ✅ EMA signal calculation based on fast vs slow EMA relationship
- ✅ Total signal calculation combining EMA signals with Bollinger Bands conditions
- ✅ Position markers for signal plotting (pointpos column)
- ✅ Configurable backcandles parameter (default: 7)
- ✅ Bullish signal (1) when fast EMA < slow EMA for all backcandles AND close >= upper Bollinger Band
- ✅ Bearish signal (2) when fast EMA > slow EMA for all backcandles AND close <= lower Bollinger Band
- ✅ No signal (0) when conditions are not met
- ✅ Optimized performance for large datasets (36,540 rows processed successfully)
- ✅ Both EMASignal and TotalSignal columns for analysis
- ✅ Position markers for chart visualization (High+1e-3 for bullish, Low-1e-3 for bearish)
- ✅ Complete backtesting functionality with proper SL/TP calculations
- ✅ Minimum distance validation to ensure proper order placement
- ✅ Market order execution with stop loss and take profit levels

### Issues Fixed:
- ✅ Column name mismatch between calculate_ma output and EMA signal expectations
- ✅ Performance issues with large DataFrame processing
- ✅ Integration of notebook logic into production strategy class
- ✅ Combined signal logic with proper Bollinger Bands integration
- ✅ Added plotting functionality for signal visualization
- ✅ Backtesting framework SL/TP validation errors
- ✅ Order placement issues with small ATR values
- ✅ Signal logic reversal (buy/sell signals were inverted)
- ✅ Minimum distance requirements for proper order validation

### Previous Task: pandas_ta Compatibility Fix

### Task Description:
Fix the pandas_ta import error in simple_scalping.py that was causing compatibility issues with newer numpy versions.

### Progress:
- [X] Identify the pandas_ta import error in simple_scalping.py
- [X] Add pandas_ta to requirements.txt with compatible version
- [X] Replace pandas_ta usage with local indicator functions
- [X] Test the fix with signals_df module
- [X] Update documentation and lessons learned

### Implementation Plan:
1. ✅ Analyze the error message and identify the root cause (pandas_ta NaN import issue)
2. ✅ Add pandas_ta to requirements.txt with compatible version
3. ✅ Replace pandas_ta functions with local indicator functions from indicators.py
4. ✅ Test the fix by running signals_df module
5. ✅ Update documentation and lessons learned

### Files Updated:
- ✅ `requirements.txt` - Added pandas_ta dependency
- ✅ `app/strategy/simple_scalping.py` - Replaced pandas_ta with local indicators
- ✅ `.cursorrules` - Updated lessons with pandas_ta compatibility guidelines

### Key Fixes Made:
- ✅ Replaced `ta.ema()` with `calculate_ma()` function
- ✅ Replaced `ta.rsi()` with `calculate_rsi()` function  
- ✅ Replaced `ta.atr()` with `calculate_atr()` function
- ✅ Implemented manual Bollinger Bands calculation
- ✅ Added missing 'rsi_period' parameter to default_params

### Issues Fixed:
- ✅ pandas_ta compatibility issue with numpy NaN import
- ✅ Missing dependencies in requirements.txt
- ✅ Dependency on external library with version conflicts
- ✅ Improved code maintainability with local functions

### Previous Task: Live Signals Bot Fix

### Task Description:
Fix the MT5Client.get_tick() method call in the live_signals.py script that was missing the required symbol parameter.

### Progress:
- [X] Identify the issue in countdown_to_next_bar() function
- [X] Fix the get_tick() method call to include TEST_SYMBOL parameter
- [X] Fix the tick data access to use dictionary format
- [X] Update error logging to use f-string formatting
- [X] Update documentation and lessons learned

### Implementation Plan:
1. ✅ Analyze the error message and identify the root cause
2. ✅ Examine the MT5Client.get_tick() method signature
3. ✅ Fix the method call to include the required symbol parameter
4. ✅ Fix the tick data access pattern
5. ✅ Update error logging for consistency
6. ✅ Update documentation and lessons learned

### Files Updated:
- ✅ `scripts/live_signals.py` - Fixed get_tick() method call and tick data access
- ✅ `.cursorrules` - Updated MT5 tick data handling lessons

### Key Fixes Made:
- ✅ Added TEST_SYMBOL parameter to get_tick() method call
- ✅ Changed tick.time to tick['time'] for dictionary access
- ✅ Fixed error logging to use f-string formatting
- ✅ Updated documentation with proper tick data handling guidelines

### Issues Fixed:
- ✅ Missing symbol parameter in get_tick() method call
- ✅ Incorrect tick data access pattern
- ✅ Inconsistent error logging format
- ✅ Missing documentation for tick data handling

### Implementation Plan:
1. ✅ Analyze the original initialize_symbols() method
2. ✅ Identify the logic issues (only adding unavailable symbols)
3. ✅ Fix the method to always attempt symbol addition
4. ✅ Add proper availability checking before attempting addition
5. ✅ Implement retry mechanism for failed symbols
6. ✅ Add comprehensive logging and debugging
7. ✅ Create helper methods for symbol management
8. ✅ Add detailed status reporting functionality
9. ✅ Create test script to verify the fix works
10. ✅ Update documentation and lessons learned

### Files Updated:
- ✅ `app/data/mt5_client.py` - Fixed initialize_symbols() method and added helper methods
- ✅ `scripts/test_symbol_initialization.py` - Test script to verify the fix
- ✅ `.cursorrules` - Updated lessons and documentation

### Key Improvements Made:
- ✅ Fixed logic to always attempt symbol addition regardless of availability
- ✅ Added proper symbol availability checking before attempting addition
- ✅ Implemented retry mechanism for failed symbol additions
- ✅ Added comprehensive logging with detailed status information
- ✅ Created helper methods: get_available_symbols(), check_symbol_availability(), get_market_watch_symbols()
- ✅ Added print_symbol_status() method for debugging
- ✅ Improved error handling and reporting
- ✅ Added proper symbol mapping verification

### Issues Fixed:
- ✅ Original method only tried to add symbols that weren't in available list
- ✅ Missing verification of symbol visibility after addition
- ✅ Inconsistent symbol mapping usage
- ✅ Lack of detailed error reporting and debugging information
- ✅ No retry mechanism for failed additions

## Previous Task: Live Trading Module Implementation

### Task Description:
Implement a comprehensive Live Trading Module using main.py as the entry point, integrating existing functionalities like notification module, strategy module, and trading module. Use swing_trend_momentum.py as the live running strategy.

### Progress:
- [X] Create real-time execution loop
- [X] Implement performance tracking
- [X] Develop failover and recovery mechanisms
- [X] Create system monitoring tools
- [X] Implement automatic restart functionality
- [X] Develop connection health checks
- [X] Create multi-account management
- [X] Implement broker communication failover
- [X] Develop system resource monitoring
- [X] Create trading hour management
- [X] Implement scheduled tasks
- [X] Develop emergency shutdown procedures
- [X] Create activity logging system
- [X] Implement strategy switching during live operation

### Implementation Plan:
1. ✅ Create comprehensive Live Trading Module structure
2. ✅ Implement LiveTrader as central orchestrator
3. ✅ Create configuration management system
4. ✅ Implement execution engine for trade management
5. ✅ Create strategy runner for SwingTrendMomentum strategy
6. ✅ Implement position manager for position tracking
7. ✅ Create risk monitor for portfolio risk management
8. ✅ Implement system monitor for health monitoring
9. ✅ Create performance tracker for metrics
10. ✅ Implement trading scheduler for market hours
11. ✅ Integrate with existing notification system
12. ✅ Update main.py to use Live Trading Module
13. ✅ Test and validate complete system

### Files Created/Updated:
- ✅ `app/live_trading/__init__.py` - Live trading module init
- ✅ `app/live_trading/config.py` - Configuration management
- ✅ `app/live_trading/live_trader.py` - Main orchestrator
- ✅ `app/live_trading/execution_engine.py` - Trade execution
- ✅ `app/live_trading/strategy_runner.py` - Strategy management
- ✅ `app/live_trading/position_manager.py` - Position tracking
- ✅ `app/live_trading/risk_monitor.py` - Risk monitoring
- ✅ `app/live_trading/system_monitor.py` - System health
- ✅ `app/live_trading/performance_tracker.py` - Performance tracking
- ✅ `app/live_trading/trading_scheduler.py` - Trading schedule
- ✅ `main.py` - Updated to use Live Trading Module
- ✅ `scripts/live_trading_example.py` - Usage example

### Key Features Implemented:
- ✅ Real-time execution loop with threading
- ✅ SwingTrendMomentum strategy integration
- ✅ Comprehensive risk management
- ✅ System health monitoring
- ✅ Performance tracking and reporting
- ✅ Trading schedule management
- ✅ Notification integration
- ✅ Crash recovery integration
- ✅ Graceful shutdown procedures
- ✅ Multi-component orchestration

## Previous Task: Web App Development - React.js + Flask

### Task Description:
Create a web application with React.js frontend and Flask backend API. The app will be built in the `/app/ui` folder.

### Progress:
- [X] Set up Flask server with CORS support
- [X] Create React.js frontend structure
- [ ] Set up API endpoints
- [ ] Implement authentication system
- [ ] Create dashboard components
- [ ] Add real-time data updates
- [ ] Implement strategy configuration interface
- [ ] Add performance visualization components

### Implementation Plan:
1. ✅ Create Flask server (server.py) with CORS support
2. ✅ Set up React.js frontend structure
3. [ ] Create API endpoints for trading data
4. [ ] Implement authentication and user management
5. [ ] Build dashboard components
6. [ ] Add real-time WebSocket connections
7. [ ] Create strategy configuration interface
8. [ ] Implement performance visualization

### Files Created:
- ✅ `app/ui/server.py` - Flask backend server with CORS and WebSocket support
- ✅ `app/ui/requirements.txt` - Python dependencies
- ✅ `app/ui/package.json` - React.js dependencies
- ✅ `app/ui/public/index.html` - Main HTML file
- ✅ `app/ui/src/index.js` - React entry point
- ✅ `app/ui/src/App.js` - Main app component with routing
- ✅ `app/ui/src/index.css` - Global styles
- ✅ `app/ui/src/components/Layout.js` - Navigation layout
- ✅ `app/ui/src/pages/Dashboard.js` - Dashboard page with system status
- ✅ `app/ui/src/pages/Trading.js` - Trading page placeholder
- ✅ `app/ui/src/pages/Strategies.js` - Strategies page placeholder
- ✅ `app/ui/src/pages/Backtesting.js` - Backtesting page placeholder
- ✅ `app/ui/src/pages/Settings.js` - Settings page placeholder
- ✅ `app/ui/src/reportWebVitals.js` - Performance monitoring
- ✅ `app/ui/README.md` - Setup and usage documentation

### Flask Server Features:
- ✅ CORS configuration for React development
- ✅ WebSocket support with Socket.IO
- ✅ API endpoints for system status, symbols, market data
- ✅ Strategy management endpoints
- ✅ Backtesting functionality
- ✅ Error handling and logging
- ✅ Production-ready configuration

### React App Features:
- ✅ Material-UI dark theme
- ✅ Responsive navigation layout
- ✅ Dashboard with system status cards
- ✅ Placeholder pages for all sections
- ✅ API integration with axios
- ✅ WebSocket client setup
- ✅ Modern React 18 structure

### Next Steps:
1. Test the Flask server and React app setup
2. Implement real-time market data streaming
3. Add trading chart components
4. Create strategy configuration forms
5. Implement backtesting interface
6. Add user authentication
7. Create performance visualization components

## Previous Tasks:
- [X] Change of Character Implementation
- [X] Break of Structure Implementation
- [X] Order Blocks Implementation
- [X] Trendline Drawing Implementation
- [X] SmartMoneyConcepts Class Implementation

## Initial Setup & Environment
- [X] Install Python 3.13.5 or latest stable version
- [X] Set up virtual environment (venv)
- [X] Install MetaTrader 5 platform and create account
- [X] Verify API access is enabled in MT5
- [X] Create requirements.txt file
- [X] Add initially required packages to requirements.txt file (MetaTrader5, pandas, numpy, etc.)
- [X] Install initial packages in requirements.txt
- [X] Create new project directory structure
- [X] Create a README.md for project description
- [X] Set up Git repository for version control
- [X] Set up .gitignore for files to ignore in git
- [X] Set up config.ini file for environment variables and credentials
- [X] Create project structure according to architecture diagram

## Core Module
- [X] Set up logging service for system-wide use
- [X] Implement main.py entry point script
- [X] Develop setup.py for system-wide configuration
- [X] Implement crash recovery mechanisms
- [] Create configuration management system
- [] Set up comprehensive error handling framework
- [] Create utility functions and helper methods
- [] Implement MT5 connection and authentication handling
- [] Develop threading or asyncio framework for concurrent operations
- [] Create system health monitoring

## MT5 Data Module
- [X] Implement MT5 client connection manager
- [X] Develop symbol management and filtering
- [X] Create OHLC data retrieval and processing
- [X] Implement tick data handling
- [X] Create data normalization and cleaning utilities
- [X] Implement real-time data streaming handlers
- [X] Develop efficient data caching mechanisms

## Trading Module
- [X] Develop order placement functions
- [X] Implement position tracking and management
- [ ] Create trade history analysis tools
- [X] Implement risk management and position sizing
- [ ] Implement market volatility metrics calculation
- [ ] Develop trade execution optimization
- [ ] Create order submission retry logic
- [X] Implement position modification capabilities
- [ ] Develop scaling in/out functionality
- [X] Create comprehensive risk limit enforcement system
- [X] Implement trade recording with full context information
- [ ] Create order book access functions
- [X] Implement different order types (Market, Limit, Stop, etc.)
- [X] Develop account balance and margin monitoring
- [ ] Create trade result handling and analysis

## Strategy Module
- [X] Implement strategy base class
- [X] Develop signal generator base function
- [X] Create entry/exit logic base class (ExitStrategy)
- [X] Implement standard technical indicators
- [X] Develop custom indicator implementations
- [ ] Create price action analysis tools
- [ ] Develop market condition identification system
- [ ] Develop multi-instrument monitoring
- [ ] Create significant price level detection
- [ ] Implement correlation tracking between instruments
- [X] Implement SmartMoneyConcepts class with comprehensive SMC analysis
- [X] Implement exit strategies:
  - [X] Fixed pip exit strategy
  - [X] ATR-based exit strategy
  - [X] Trailing stop exit strategy
- [ ] Implement specific strategies:
  - [X] Trend following strategy implementation
  - [ ] Mean reversion strategy implementation
  - [ ] Breakout strategy implementation
  - [ ] Scalping strategy implementation
- [ ] Create multi-timeframe signal confirmation
- [ ] Implement pattern recognition algorithms
- [X] Develop trailing stop exit strategies
- [ ] Implement partial position exit logic
- [ ] Create strategy parameter management
- [ ] Develop strategy selection based on market conditions
- [ ] Implement strategy results tracking
- [ ] Create strategy performance metrics

## Strategy Module Lessons

- For strategy development:
  - Use abstract base classes for consistent interface
  - Implement proper parameter validation
  - Use pandas DataFrames for signal generation
  - Follow the signal convention: 1 for buy, -1 for sell, 0 for no signal
  - Implement comprehensive logging for strategy execution
  - Use type hints for better code maintainability
  - Test strategies with historical data before live trading
  - Implement proper error handling for edge cases
  - Use modular design for easy strategy composition
  - Document strategy logic and parameters clearly

- For exit strategy design:
  - Separate entry logic (BaseStrategy) from exit logic (ExitStrategy)
  - Use composition over inheritance for exit strategies
  - Implement multiple exit strategy types (fixed pip, ATR-based, trailing stops)
  - Validate exit strategy parameters at initialization
  - Support dynamic exit level calculation based on market conditions
  - Implement trailing stop updates for ongoing position management
  - Use symbol information for proper pip value calculations
  - Log exit level calculations for debugging and analysis
  - Support both stop loss and take profit levels
  - Allow strategies to work without exit strategies (optional composition)

## Analysis Module
- [ ] Create performance tracking system
- [ ] Implement equity curve calculation
- [ ] Develop trade analytics for statistics
- [ ] Create drawdown analysis tools
- [ ] Implement performance report generation
- [ ] Develop KPI calculation system
- [ ] Create trade pattern identification logic
- [ ] Implement expectancy and risk-adjusted return calculations
- [ ] Develop market condition performance analysis
- [ ] Create performance anomaly detection system
- [ ] Implement performance visualization tools
- [ ] Create historical performance comparison
- [ ] Develop timeframe-specific performance analysis
- [ ] Implement strategy attribute correlation analysis

## Backtest Module
- [ ] Implement event-based backtesting engine
- [ ] Create historical data processing for testing
- [ ] Develop realistic slippage and commission modeling
- [ ] Implement bootstrapping techniques
- [ ] Create historical market condition simulation
- [ ] Develop test result storage and comparison
- [ ] Implement backtesting reporting system
- [ ] Create visualization of trade entries and exits
- [ ] Develop forward testing capability on demo accounts
- [ ] Implement backtesting acceleration techniques
- [ ] Create stress testing scenarios
- [ ] Develop benchmark strategy comparison
- [ ] Implement custom backtest metrics calculation
- [ ] Create backtesting data integrity validation

## Optimization Module
- [ ] Create parameter optimization for strategies
- [ ] Develop walk-forward analysis system
- [ ] Implement Monte Carlo simulation
- [ ] Create cross-validation framework
- [ ] Develop optimization metric scoring functions
- [ ] Create multi-objective optimization algorithms
- [ ] Develop parameter stability analysis
- [ ] Implement confidence interval calculations
- [ ] Create visualization for parameter sensitivity
- [ ] Develop overfitting prevention mechanisms
- [ ] Implement optimization report generation
- [ ] Create genetic algorithm optimization
- [ ] Develop Bayesian optimization capabilities
- [ ] Implement grid search optimization
- [ ] Create optimization job distribution system
- [ ] Develop parameter correlation analysis
- [ ] Implement hyperparameter optimization
- [ ] Create optimization result comparison tools
- [ ] Develop robustness testing framework

## Dashboard Module
- [ ] Set up web framework (Flask/FastAPI)
- [ ] Create dashboard main page
- [ ] Implement strategy configuration interface
- [ ] Develop performance visualization components
- [ ] Create authentication system
- [ ] Implement user permission system
- [ ] Create data API endpoints
- [ ] Develop chart components for trade visualization
- [ ] Create equity curve display
- [ ] Implement indicator visualization
- [ ] Create alert configuration and management
- [ ] Develop configuration validation system
- [ ] Implement responsive design for multiple devices
- [ ] Create real-time data updates using WebSockets
- [ ] Develop interactive reports and analytics

## Database Module
- [ ] Set up TimescaleDB connection
- [ ] Create database schema design
- [ ] Implement data persistence management
- [ ] Develop query optimization for performance
- [ ] Create backup and restore functionality
- [ ] Implement data export functions
- [ ] Create efficient data compression for history
- [ ] Develop query builder helpers
- [ ] Implement ORM (SQLAlchemy) integration
- [ ] Create migration system for schema updates
- [ ] Develop data partitioning strategy
- [ ] Implement connection pooling
- [ ] Create database monitoring tools
- [ ] Develop data integrity verification

## External Integration Module
- [X] Implement notification service:
  - [X] Email alert system
  - [X] Telegram bot integration
  - [X] SMS notification (optional)
- [ ] Create external data integrations:
  - [ ] News API client
  - [ ] Economic calendar integration
  - [ ] Fundamental data retrieval
- [ ] Develop import/export functionality:
  - [ ] Strategy import/export
  - [ ] Historical data import/export
  - [ ] Configuration import/export
- [ ] Create web scraping tools for market data
- [ ] Implement social sentiment analysis
- [ ] Develop secure API key management
- [ ] Create webhook handlers for external triggers
- [ ] Implement third-party service monitoring

## Live Trading Module
- [X] Create real-time execution loop
- [X] Implement performance tracking
- [X] Develop failover and recovery mechanisms
- [X] Create system monitoring tools
- [X] Implement automatic restart functionality
- [X] Develop connection health checks
- [X] Create multi-account management
- [X] Implement broker communication failover
- [X] Develop system resource monitoring
- [X] Create trading hour management
- [X] Implement scheduled tasks
- [X] Develop emergency shutdown procedures
- [X] Create activity logging system
- [X] Implement strategy switching during live operation

## Testing
- [ ] Set up testing framework (pytest)
- [ ] Create unit tests for all core components
- [ ] Implement integration tests for module interactions
- [ ] Develop backtesting validation suite
- [ ] Create tests for error handling and recovery
- [ ] Implement performance benchmark tests
- [ ] Develop API endpoint tests
- [ ] Create test fixtures and mock data
- [ ] Implement continuous integration pipeline
- [ ] Document testing procedures
- [ ] Create MT5 API mocking system
- [ ] Implement code coverage reporting
- [ ] Develop automated regression tests
- [ ] Create stress testing framework

## Documentation
- [ ] Create user documentation:
  - [ ] Installation and setup guide
  - [ ] Configuration manual
  - [ ] Trading strategy descriptions
  - [ ] Troubleshooting guide
- [ ] Develop developer documentation:
  - [ ] Architecture overview
  - [ ] API reference
  - [ ] Extension guide
  - [ ] Development environment setup
- [ ] Create operations documentation:
  - [ ] Deployment procedures
  - [ ] Backup and recovery guide
  - [ ] Performance tuning recommendations
  - [ ] Security considerations
- [ ] Implement docstrings for all functions and classes
- [ ] Create markdown files for GitHub repository
- [ ] Develop sample configuration guides
- [ ] Create API documentation using OpenAPI/Swagger
- [ ] Implement automatic documentation generation

## Deployment & Operation
- [ ] Create deployment scripts for different environments
- [ ] Implement versioning system
- [ ] Create Docker containerization (optional)
- [ ] Develop installation guides
- [ ] Create configuration migration tools
- [ ] Implement rollback procedures
- [ ] Develop release testing protocol
- [ ] Create changelog generation process
- [ ] Implement license management
- [ ] Prepare system requirement documentation
- [ ] Create automated deployment pipeline
- [ ] Develop monitoring dashboard
- [ ] Implement log rotation and archiving
- [ ] Create system performance benchmark tools

## Compliance & Security
- [ ] Implement appropriate risk warnings
- [ ] Create comprehensive audit logging
- [ ] Develop secure credential storage
- [ ] Implement role-based access control
- [ ] Create data encryption for sensitive information
- [ ] Develop compliance reporting features
- [ ] Implement trade record archiving
- [ ] Create security review documentation
- [ ] Develop privacy policy and terms of use
- [ ] Implement broker-specific compliance features
- [ ] Create data retention policy
- [ ] Implement secure API communication
- [ ] Develop vulnerability scanning integration
- [ ] Create penetration testing framework

## Performance Optimization
- [ ] Conduct performance profiling
- [ ] Optimize tick processing latency
- [ ] Improve memory usage patterns
- [ ] Optimize database queries
- [ ] Improve API response times
- [ ] Reduce CPU usage during idle periods
- [ ] Optimize data processing pipelines
- [ ] Improve startup time
- [ ] Optimize backtest performance
- [ ] Create performance monitoring dashboards
- [ ] Implement caching strategies
- [ ] Develop database indexing optimization
- [ ] Create asynchronous processing where applicable
- [ ] Implement data preprocessing optimization

## Maintenance & Roadmap Planning
- [ ] Plan version update schedule
- [ ] Create feature roadmap document
- [ ] Develop user feedback collection system
- [ ] Implement analytics for feature usage
- [ ] Create bug tracking and reporting process
- [ ] Develop backward compatibility policy
- [ ] Create deprecation policy for features
- [ ] Plan future API integration roadmap
- [ ] Document technical debt and refactoring needs
- [ ] Create long-term architecture evolution plan
- [ ] Develop community contribution guidelines
- [ ] Create plugin/extension system plans
- [ ] Implement update notification system
- [ ] Develop feature request prioritization framework

## Additional MT5-Specific Tasks
- [ ] Implement MT5 terminal state monitoring
- [ ] Create MT5 server status tracking
- [ ] Develop MT5 connection retry with exponential backoff
- [ ] Implement proper MT5 resource cleanup
- [ ] Create MT5 session time handling
- [ ] Develop MT5 symbol properties caching
- [ ] Implement proper MT5 timezone management
- [ ] Create MT5 account type-specific features
- [ ] Develop MT5 order filling policy handling
- [ ] Implement MT5 terminal GUI automation (if needed)
- [ ] Create MT5 expert advisor interaction (if applicable)
- [ ] Develop MT5 custom indicator access
- [ ] Implement MT5 market depth data processing
- [ ] Create tools for MT5 backtesting data preparation